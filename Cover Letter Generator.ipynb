{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Az-Data/Portfolio/blob/master/Cover%20Letter%20Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnkgHSIXDUag"
      },
      "source": [
        "# Cover Letter Generator\n",
        "\n",
        "I am utilizing OpenAI's API to generate cover letters, aiming to streamline the process as I apply for jobs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "8G2nxhqgSt43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the .env file that contains your OpenAI API key"
      ],
      "metadata": {
        "id": "qeguADOcS3YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the below and run this cell if you are running this notebook in Google Colab\n",
        "%%capture\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "6f0WfFDqDtGo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "xmPXTk-uSyZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aLrJfdMVDUaj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())\n",
        "openai.api_key = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VLJx3H_BDUal"
      },
      "outputs": [],
      "source": [
        "# Paste job ad text in the job_ad variable\n",
        "\n",
        "job_ad = \"\"\"\n",
        "Company description:\n",
        "\n",
        "At Stockland we are a community delivering outcomes that benefit the community at large. We work collaboratively and inclusively, building strong working relationships. Our portfolio is diverse and so are the opportunities for professional and career development. We are committed to providing our people with broad experiences to build a successful career.\n",
        "\n",
        "We recognise the importance of flexibility and work life-quality and over 80% of our employees have informal or formal flexible work arrangements. Additionally, Stockland has a strong commitment to achieving the best outcomes through an inclusive and collaborative culture. Our customers come from diverse backgrounds and we want our teams to reflect this.\n",
        "\n",
        "Job description:\n",
        "\n",
        "Data Analyst - Investment Management\n",
        "\n",
        "Location: Sydney, NSW with flexibility to manage working from CBD office, Stockland Assets and Home\n",
        "\n",
        "We have an exciting opportunity for a Data Analyst to join our team in Sydney.\n",
        "\n",
        "This role is responsible for supporting business decisions by providing in depth and quality analysis of various data sets including but not limited to leasing, sales, traffic, feedback and debt trends. Working as part of a team, you will be able to directly contribute to the success of the Stockland Investment Management portfolio across all Asset classes including Retail Town Centres, Workplace, Logistics and Community Real Estate.\n",
        "\n",
        "Key Responsibilities:\n",
        "• Ensuring accurate and timely reporting for the portfolio, including appropriate analysis and commentary.\n",
        "• Identify key trends affecting Stockland portfolio to identify risks and opportunities.\n",
        "• Assisting management and trend analysis/Quarterly and yearly reporting.\n",
        "• Driving alignment with all business units for reporting and insights provided to the business.\n",
        "• Identifying and recommending improvements to reporting systems, processes, and tools to improve decision making.\n",
        "• Providing ad hoc support across various data requirements.\n",
        "• Build and maintain strong working relationships with key stakeholders\n",
        "\n",
        "\n",
        "To be successful in this role:\n",
        "You will be an experienced professional with the ability to quickly connect the dots and build understanding of Stockland's business. You will be comfortable communicating data sets and reports to senior stakeholders.\n",
        "\n",
        "In addition you will have the following skills experience and qualifications:\n",
        "• Relevant tertiary qualifications (Business, Mathematics, Statistics, Economics) and/or have relevant experience in analytics/reporting roles, ideally in property or retail.\n",
        "• Experience using analytics software such as Power Bi, SQL and Python is advantageous but not essential\n",
        "• Advanced skills in MS Excel and MS PowerPoint\n",
        "• Excellent written and verbal communication skills and a keen eye for detail\n",
        "\n",
        "The Stockland Proposition\n",
        "\n",
        "At Stockland we are a community delivering outcomes that benefit the community at large. We work collaboratively and inclusively, building strong working relationships. Our portfolio is diverse and so are the opportunities for professional and career development. We are committed to providing our people with broad experiences to build a successful career.\n",
        "\n",
        "We recognise the importance of flexibility and work life-quality and over 80% of our employees have informal or formal flexible work arrangements. Additionally, Stockland has a strong commitment to achieving the best outcomes through an inclusive and collaborative culture. Our customers come from diverse backgrounds and we and we want our teams to reflect this.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hz0sbVErDUan"
      },
      "outputs": [],
      "source": [
        "work_history = \"\"\"\n",
        "Data Visualisation Engineer - Transport for NSW (Apr-2022 - May-2024)\n",
        "Challenge: In my most recent engagement, I worked on a project with the Health & Safety team within Transport for NSW. The aim of the project was to consolidate health and safety data from all areas of the organization so it could be effectively utilized by the Health & Safety team.\n",
        "In my most recent role as a Data Visualization Engineer at Transport for NSW, I was involved in a project focused on consolidating health and safety data from different parts of the organisation. This involved building business-facing Power BI reports and developing the necessary Power BI infrastructure. I utilized DAX and Power Query to create advanced reports and Power BI apps tailored to the business needs. Specifically, I employed DAX to calculate and visualize Health and Safety KPIs. I also developed reports and datasets across two separate Power BI workspaces, leveraging Power Query to automate data extraction when saving into different workspaces.\n",
        "These Power BI reports were connected to a Snowflake database, where I used SQL scripts to validate, analyse, troubleshoot, and test the data consumed by the reports. This included developing scripts to ensure proper data masking within the Snowflake views. Over the course of two years, I worked through multiple production releases, each introducing new data sources and requiring updates to the Power BI reports, datasets, and models.\n",
        "Additionally, I always create and maintain very detailed documentation for myself, other developers, and end users to reference. The documentation I created for my last role was around 100 pages long, discussing the technical solution and all the configurations for the Power BI environment. On top of that, I created walkthrough videos for each of the Power BI reports for users and stakeholders.\n",
        "\n",
        "Role and achievements: I was responsible for creating business-facing Power BI reports and building the Power BI infrastructure for the Health & Safety team. Delivered solution included:\n",
        "-\tDeveloped data models\n",
        "-\tDesigned dashboards\n",
        "-\tImplemented a comprehensive Power BI infrastructure, including multiple Power BI Apps and Reports\n",
        "-\tEnsured different user groups had access to different aspects of the Apps, Reports and Data using Row and Object Level security\n",
        "-\tDeveloped Documentation\n",
        "-   Creating and Implementing Snowflake Data quality test cases\n",
        "Skills utilised:  Data Visualisation, Data Modeling and Design\n",
        "Tools and technologies utilised: Power BI, Tableau, SQL (Snowflake), Python\n",
        "\n",
        "Power BI/Data engineer - L'Oreal (Mar-2022 & Jul-2021 - Sep-2021)\n",
        "Challenge: The goal was to create a proof-of-concept solution to process raw files from cloud storage and store them in Google Cloud Platform (GCP) BigQuery. This would allow users to analyse data, build visualisations, or develop models by connecting directly to BigQuery.\n",
        "Role and achievements: I was the primary developer responsible for building an ETL solution to ingest analytics data on GCP. By utilizing GCP Python APIs and Google's serverless container service, I ingested and transformed multiple files that were continually updated from Google Cloud Storage into BigQuery. I then presented the final solution to stakeholders, along with detailed documentation enabling other developers to replicate and extend the solution.\n",
        "Skills utilised: Data Engineering, Data Modeling and Design\n",
        "Tools and technologies utilised: Google Cloud Platform; BigQuery, Cloud Storage, Apache Airflow, Cloud Run\n",
        "\"\"\"\n",
        "\n",
        "headers = \"\"\"\n",
        "Name: Aaron Fernandes\n",
        "City, State, Zip: Parramatta, NSW, 2150\n",
        "Email Address: akfernandi@gmail.com\n",
        "Phone Number: 0424 108 130\n",
        "\"\"\"\n",
        "\n",
        "company_name = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ahzLkylQDUan",
        "outputId": "7950d1e2-605b-449e-e53f-01127125f040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Today's Date]\n",
            "\n",
            "Hiring Manager\n",
            "Stockland\n",
            "[Company Address]\n",
            "[City, State, Zip]\n",
            "\n",
            "Dear Hiring Manager,\n",
            "\n",
            "I am writing to express my interest in the Data Analyst - Investment Management position at Stockland, as advertised. With a proven track record in data visualization, data modeling, and design, gained through my roles as a Data Visualization Engineer at Transport for NSW and a Power BI/Data Engineer at L'Oreal, I am excited about the opportunity to contribute to Stockland's Investment Management team.\n",
            "\n",
            "Throughout my tenure at Transport for NSW, I spearheaded a strategic project focused on consolidating health and safety data to empower the Health & Safety team. Leveraging advanced Power BI skills, I built intricate data models, designed interactive dashboards, and developed a comprehensive Power BI infrastructure to ensure seamless data utilization. Additionally, my proficiency in SQL enabled me to validate and optimize data in Snowflake databases, ensuring accurate reporting and analysis for key stakeholders.\n",
            "\n",
            "At L'Oreal, I led the development of an ETL solution on Google Cloud Platform, demonstrating my aptitude for data engineering and modeling. By seamlessly ingesting and transforming data into BigQuery using GCP Python APIs, Cloud Storage, and Cloud Run, I enabled stakeholders to harness data for analytical insights and decision-making.\n",
            "\n",
            "I am particularly impressed by Stockland's commitment to diversity, inclusivity, and fostering a collaborative work culture. I firmly believe that my technical expertise in tools such as Power BI, SQL, Python, and Google Cloud Platform aligns perfectly with the requirements of the role. Moreover, my experience in creating detailed documentation, walkthrough videos, and ensuring data quality attest to my dedication to delivering high-quality and user-friendly solutions.\n",
            "\n",
            "I am excited about the opportunity to bring my unique skill set to Stockland and contribute to the success of the Investment Management portfolio. I am confident that my analytical capabilities, attention to detail, and passion for leveraging data for strategic decision-making make me a strong fit for this position.\n",
            "\n",
            "Thank you for considering my application. I look forward to the possibility of discussing how my background, skills, and enthusiasm align with Stockland's vision in further detail.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "Aaron Fernandes\n",
            "Email: akfernandi@gmail.com\n",
            "Phone: 0424 108 130\n"
          ]
        }
      ],
      "source": [
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def generate_cover_letter(job_ad, work_history):\n",
        "    # Create the messages structure for the chat completion API\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional career assistant. Your task is to write a personalized cover letter.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Job Ad: {job_ad}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"My Work History: {work_history}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"My Personal Details: {headers}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Company Name: {company_name}\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Write a compelling and customized cover letter tailored to the job position based on the job ad and work history. Omit my Address, and put todays date\"}\n",
        "    ]\n",
        "\n",
        "    # Generate a response from the model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"text\"},\n",
        "    )\n",
        "\n",
        "    # Return the assistant's message (the cover letter)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Generate the cover letter\n",
        "cover_letter = generate_cover_letter(job_ad, work_history)\n",
        "print(cover_letter)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}