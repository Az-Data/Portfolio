{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Summariser (WIP)\n",
    "\n",
    "I am part of a book club, and I wanted the ability to go back and review books I've already read and question the text. \n",
    "Example use would be to find out:\n",
    "- What themes were prominent in the book? \n",
    "- What would be some open ended questions that can drive discussion about aspects about this book? \n",
    "- Get a description of all the main characters in the book.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am having trouble uploading a file to the genai api. Possible things to try:\n",
    "- Try running this in Colab\n",
    "- Try using the Vertex API if that doesn't work. \n",
    "- Find out how to get a similar experience of Google AI studios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import zipfile\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import mimetypes\n",
    "import time\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ.get('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def book_text(file_path):\n",
    "    \"\"\"reads the book text into memory as a string to feed a prompt.\n",
    "\n",
    "    Args:\n",
    "      file_path: path to the book txt file. \n",
    "\n",
    "    Returns:\n",
    "      String of the book text.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def summarize_text(book_text):\n",
    "    \"\"\"Summarizes a text file using the Gemini API.\n",
    "\n",
    "    Args:\n",
    "      book_text: the book text as a string.\n",
    "\n",
    "    Returns:\n",
    "      A summary of the text.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(f\"Please provide a concise summary of the following Book:\\n\\n{book_text}\")\n",
    "    # response = genai.generate_content(\n",
    "    #     model=\"gemini-pro\",\n",
    "    #     prompt=f\"Please provide a concise summary of the following Book:\\n\\n{book_text}\",\n",
    "    # )\n",
    "    return response.result\n",
    "\n",
    "\n",
    "def gemini_prompt(book_text, my_prompt):\n",
    "    \"\"\"Allows you to ask questions about the following book text.\n",
    "\n",
    "    Args:\n",
    "      book_text: the book text as a string.\n",
    "      my_prompt: the prompt.\n",
    "\n",
    "    Returns:\n",
    "      answer from gemini api.\n",
    "    \"\"\"        \n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(f\"Please provide a concise summary of the following Book:\\n\\n{book_text}\")\n",
    "    # response = genai.generate_text(\n",
    "    #     model=\"gemini-pro\",\n",
    "    #     prompt=f\"Please provide a concise summary of the following Book:\\n\\n{book_text}\",\n",
    "    # )\n",
    "    return response.result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine MIME type\n",
    "# mime_type, _ = mimetypes.guess_type(\"book_output copy.txt\")\n",
    "# if mime_type is None:\n",
    "#     mime_type = \"application/octet-stream\"  # Fallback to generic type\n",
    "\n",
    "# # Upload the file\n",
    "# with open(file_path, \"r\") as f:\n",
    "#     file_contents = f.read()\n",
    "\n",
    "# import pathlib\n",
    "\n",
    "# media = pathlib.Path(__file__).parents[1] / \"third_party\"\n",
    "\n",
    "# file_hash = genai.upload_file(media / \"book_output copy.txt\")\n",
    "\n",
    "# print(file_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Example usage\n",
    "# file_path = \"book_output copy.txt\"  # Replace with your file path\n",
    "# query = \"Return a summary of the following book\"\n",
    "# response = upload_and_query_file(file_path, query)\n",
    "# print(response)\n",
    "\n",
    "\n",
    "# -------------------------------------\n",
    "\n",
    "# book_txt = book_text(\"book_output.txt\")\n",
    "# summarize_text(book_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def upload_to_gemini(path, mime_type=None):\n",
    "  \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "  \"\"\"\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file\n",
    "\n",
    "def wait_for_files_active(files):\n",
    "  \"\"\"Waits for the given files to be active.\n",
    "\n",
    "  Some files uploaded to the Gemini API need to be processed before they can be\n",
    "  used as prompt inputs. The status can be seen by querying the file's \"state\"\n",
    "  field.\n",
    "\n",
    "  This implementation uses a simple blocking polling loop. Production code\n",
    "  should probably employ a more sophisticated approach.\n",
    "  \"\"\"\n",
    "  print(\"Waiting for file processing...\")\n",
    "  for name in (file.name for file in files):\n",
    "    file = genai.get_file(name)\n",
    "    while file.state.name == \"PROCESSING\":\n",
    "      print(\".\", end=\"\", flush=True)\n",
    "      time.sleep(10)\n",
    "      file = genai.get_file(name)\n",
    "    if file.state.name != \"ACTIVE\":\n",
    "      raise Exception(f\"File {file.name} failed to process\")\n",
    "  print(\"...all files ready\")\n",
    "  print()\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# You may need to update the file paths\n",
    "files = [\n",
    "  upload_to_gemini(\"book_output.txt\", mime_type=\"text/plain\"),\n",
    "]\n",
    "\n",
    "# Some files have a processing delay. Wait for them to be ready.\n",
    "wait_for_files_active(files)\n",
    "\n",
    "chat_session = model.start_chat()\n",
    "\n",
    "response = chat_session.send_message(\"List all the characters of the uploaded book, from most important to least important\")\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def epub_to_text(epub_path):\n",
    "#     \"\"\"Converts an EPUB file to a plain text file.\n",
    "\n",
    "#     Args:\n",
    "#       epub_path: Path to the EPUB file.\n",
    "\n",
    "#     Returns:\n",
    "#       The extracted plain text.\n",
    "#     \"\"\"\n",
    "\n",
    "#     text = \"\"\n",
    "#     with zipfile.ZipFile(epub_path, 'r') as zf:\n",
    "#         for filename in zf.namelist():\n",
    "#             if filename.endswith('.html') or filename.endswith('.xhtml'):\n",
    "#                 with zf.open(filename) as f:\n",
    "#                     content = f.read().decode('utf-8')\n",
    "#                     soup = BeautifulSoup(content, 'html.parser')\n",
    "#                     text += soup.get_text()\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after I convert the epub to text I will go in and edit the text to make it easier to read when I feed it into gemini.\n",
    "# book_txt = epub_to_text(r\"C:\\Users\\harpo\\Desktop\\A Darker Shade of Magic.epub\")\n",
    "# with open(\"book_output.txt\", \"w\") as f:\n",
    "#     f.write(book_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
